{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMoV2XVS9SdIrFMcLGZe7t9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabioMMaia/face_recognition_4models/blob/main/CNN_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "tqdm.pandas()\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from skimage import data, exposure\n",
        "semente = 42\n",
        "import json\n",
        "\n",
        "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "KicCwdkY_iNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz"
      ],
      "metadata": {
        "id": "jKoSfOARLYQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_dir = '/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/config/'\n",
        "model_save_dir = '/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/model/'\n",
        "erro_dir = '/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/error/'\n",
        "log_dir = '/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/log/'\n",
        "\n",
        "num_classes = 50\n",
        "tag = '_' + str(num_classes) + '_classes'"
      ],
      "metadata": {
        "id": "qVMs091XckBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def write_log(s):\n",
        "#     with open(pasta +'CNN_config.txt','a') as f:\n",
        "#       print(s, file=f)\n",
        "\n",
        "# model_name = 'AlexNet'\n",
        "# ref = datetime.now().strftime(\"%Y%m%d\")\n",
        "# model_ref = model_name + '_' + ref\n",
        "\n",
        "# resultadoFile = open(pasta + 'CNN_config.txt', 'w')\n",
        "# data_atual = datetime.now(pytz.timezone('America/Bahia')).strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "# print('Execução em:', data_atual, file=resultadoFile)\n",
        "# resultadoFile.close()"
      ],
      "metadata": {
        "id": "ateQCJGAcfPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "EUaDDb1oYXAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "G-MIyKpvYhW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "739PfpmdHeJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#- Carrega Labels e Informações da Imagens"
      ],
      "metadata": {
        "id": "JKOqKrkxMaOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images_characteristics(dataset_images):\n",
        "  aux_imgs = subselect.merge(dataset_images[['images']], left_index=True, right_index=True, how='inner')\n",
        "  aux_imgs = aux_imgs.merge(celebs_attributes,  left_index=True, right_index=True, how='left')\n",
        "\n",
        "  for coluna in aux_imgs.columns:\n",
        "    if coluna not in ['id','class']:\n",
        "      try:\n",
        "        print(coluna, 'amostras positivas:', aux_imgs[aux_imgs[coluna]==True].shape[0])\n",
        "        fig, axes = plt.subplots(1,5, figsize=(10,12))\n",
        "        for (i,row), ax in zip(aux_imgs[aux_imgs[coluna]==True].head(5).iterrows(), axes.ravel()): \n",
        "          ax.axis('off')\n",
        "          ax.imshow(row['images'])\n",
        "        plt.show()\n",
        "      except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "znOtvfZ4xyy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_by_n_class(n):\n",
        "  topn_classes = labels['class'].value_counts().head(n).index\n",
        "  keep_images = labels[(labels['class'].isin(topn_classes)) & ~(labels.index.get_level_values(0).isin(blurry_images))].index\n",
        "  subselect = labels[labels['class'].isin(topn_classes)]\n",
        "\n",
        "  print('foram retornadas imagens {} de pessoas {} o que corresponde a {}% da base'.format(\n",
        "      subselect.shape[0], \n",
        "      len(subselect['class'].unique()),\n",
        "      round(100*subselect.shape[0]/labels.shape[0],2)))\n",
        "  \n",
        "  return keep_images"
      ],
      "metadata": {
        "id": "9WSeppJduFZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_by_freq(ratio):\n",
        "  assert ratio>0 and ratio<1, 'Ratio deve ser entre 0 e 1'\n",
        "  import math\n",
        "  keep_class = labels['class'].value_counts().cumsum()\n",
        "  final_list = keep_class[:(keep_class <= math.ceil(labels.shape[0]*ratio)).sum() + 1].index\n",
        "  subselect = labels[labels['class'].isin(final_list)]\n",
        "  return subselect"
      ],
      "metadata": {
        "id": "jJf01V-AW49t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels():\n",
        "  labels= pd.read_csv(r'/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/Data/identity_CelebA.txt', header=None)\n",
        "\n",
        "  labels.rename(columns={0:'id'},inplace=True)\n",
        "\n",
        "  labels['class'] = labels['id'].apply(lambda x:x.split()[1])\n",
        "  labels['class'] = labels['class'].astype(int)\n",
        "  labels['image'] = labels['id'].apply(lambda x:x.split()[0])\n",
        "\n",
        "  labels.set_index('image', inplace=True)\n",
        "\n",
        "  return labels"
      ],
      "metadata": {
        "id": "MOOvJdvFBovZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_celeb_attributes():\n",
        "  celebs_attributes = pd.read_csv(r'/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/Data/list_attr_celeba.csv')\n",
        "  celebs_attributes.set_index('image_id', inplace=True)\n",
        "  m_sample =  celebs_attributes.shape[0]\n",
        "  print('Total de {} imagens'.format(m_sample))\n",
        "  celebs_attributes=celebs_attributes.apply(lambda x:x>0)\n",
        "  celebs_attributes =celebs_attributes.merge(labels, left_index=True, right_index=True, how ='inner')\n",
        "  assert celebs_attributes.shape[0]==m_sample\n",
        "  return celebs_attributes\n"
      ],
      "metadata": {
        "id": "XdyiEn8eiLh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = get_labels()\n",
        "celebs_attributes = get_celeb_attributes()"
      ],
      "metadata": {
        "id": "RjEJXFSoN5ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blurry_images = celebs_attributes[(celebs_attributes['Blurry'])]\n",
        "\n",
        "print('numero de amostras c/ caracteristicas:', blurry_images.shape[0] )\n",
        "print('percentual da base:', blurry_images.shape[0]/labels.shape[0] )\n",
        "\n",
        "blurry_images = blurry_images.index"
      ],
      "metadata": {
        "id": "EeV0-3pvsJVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keep_images  = filter_by_n_class(num_classes)"
      ],
      "metadata": {
        "id": "K0KO0LFQOO7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(save=False):\n",
        "  import zipfile\n",
        "  from tqdm import tqdm\n",
        "  from PIL import Image\n",
        "  from skimage.transform import resize\n",
        "\n",
        "  imagens_path = '/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/CelebA/img_align_celeba.zip'\n",
        "  imgzip = zipfile.ZipFile(imagens_path)\n",
        "  inflist = imgzip.infolist()\n",
        "  all_images = {}\n",
        "\n",
        "  # Testando com imagens da classe 3\n",
        "\n",
        "  for f in tqdm(inflist):\n",
        "    file_name = f.filename.split('/')[1]\n",
        "    if file_name in keep_images:\n",
        "    # if '.jpg' in file_name:\n",
        "      ifile = imgzip.open(f)\n",
        "      img = Image.open(ifile)\n",
        "      img_resize = resize(np.array(img), (128, 128))\n",
        "      all_images[file_name] = img_resize\n",
        "\n",
        "  return all_images\n",
        "\n",
        "  if save:\n",
        "    with open(r\"/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/Data/images_raw_resized_top\"+str(n)+\".obj\", \"wb\") as fp:\n",
        "        pickle.dump(dataset_raw, fp)\n",
        "\n",
        "        \n",
        "all_images = load_images()   "
      ],
      "metadata": {
        "id": "v_AUw1rzIqNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_raw = pd.DataFrame({'img':all_images.keys(), 'images':all_images.values()})\n",
        "dataset_raw.set_index('img', inplace=True)\n",
        "dataset_raw = dataset_raw.merge(labels, left_index=True, right_index=True,how='left')\n",
        "n_classes = len(dataset_raw['class'].unique())"
      ],
      "metadata": {
        "id": "tlrUITS6CmUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images_class():\n",
        "  for class_sample in dataset_raw['class'].unique()[:5]:\n",
        "    fig, axes = plt.subplots(5,5, figsize=(10,12))\n",
        "    print('class:{}'.format(class_sample))\n",
        "\n",
        "    for (i,row), ax in zip(dataset_raw[dataset_raw['class']==class_sample][['images']].head(25).iterrows(), axes.ravel()): \n",
        "      ax.axis('off')\n",
        "      ax.imshow(row['images'])  \n",
        "    plt.show()\n",
        "\n",
        "show_images_class()"
      ],
      "metadata": {
        "id": "jatVQkHWUSNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_n= dataset_raw['class'].unique()\n",
        "num_classes = len(classes_n)\n",
        "indexes = np.arange(0,len(classes_n))\n",
        "\n",
        "conversor_classes = {classes_n[i]: indexes[i] for i in range(len(classes_n))}\n",
        "conversor_classes_inv = {v: k for k, v in conversor_classes.items()}\n",
        "\n",
        "dataset_raw['class_n'] = dataset_raw['class'].map(conversor_classes)"
      ],
      "metadata": {
        "id": "ONDL1TKeEmrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(list(dataset_raw['images'].values))\n",
        "n_saidas = len(dataset_raw['class'].unique())\n",
        "target = keras.utils.to_categorical(dataset_raw['class_n'].values, n_saidas).astype('int32')"
      ],
      "metadata": {
        "id": "RRgmor9DBGCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images, target, stratify=target, test_size=0.30, random_state=24)"
      ],
      "metadata": {
        "id": "ZjdN6mrJFK_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensões\n",
        "img_lin, img_col, n_channels = X_train.shape[1], X_train.shape[2],X_train.shape[3]\n",
        "input_shape = (img_lin, img_col, n_channels)\n",
        "n_saidas = len(dataset_raw['class'].unique())\n",
        "\n",
        "# Semente\n",
        "# as sementes ajudam a ter resultados reproduzíveis\n",
        "from numpy.random import seed\n",
        "from tensorflow.random import set_seed\n",
        "seed(semente)\n",
        "set_seed(semente)\n",
        "\n",
        "# vamos usar o mesmo número de épocas e batchsize para ambos\n",
        "batch_size = 100\n",
        "epochs = 10_000\n",
        "\n",
        "# Criterio de parada\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200)\n",
        "\n",
        "# Loss\n",
        "loss = 'categorical_crossentropy'\n",
        "adam_optimizer = keras.optimizers.Adam()\n",
        "metrics_evaluation = [tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.AUC()]"
      ],
      "metadata": {
        "id": "eOfTchlRBQK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AlexNet_model():\n",
        "  AlexNet = keras.models.Sequential()\n",
        "  AlexNet.add(keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape= input_shape))\n",
        "  AlexNet.add(keras.layers.BatchNormalization())\n",
        "  AlexNet.add(keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "  AlexNet.add(keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "  AlexNet.add(keras.layers.BatchNormalization())\n",
        "  AlexNet.add(keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "  AlexNet.add(keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "  AlexNet.add(keras.layers.BatchNormalization())\n",
        "  AlexNet.add(keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "  AlexNet.add(keras.layers.BatchNormalization())\n",
        "  AlexNet.add(keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "  AlexNet.add(keras.layers.BatchNormalization())\n",
        "  AlexNet.add(keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),padding='same'))\n",
        "  AlexNet.add(keras.layers.Flatten())\n",
        "  AlexNet.add(keras.layers.Dense(4096, activation='relu'))\n",
        "  AlexNet.add(keras.layers.Dropout(0.5))\n",
        "  AlexNet.add(keras.layers.Dense(4096, activation='relu'))\n",
        "  AlexNet.add(keras.layers.Dropout(0.5))\n",
        "  AlexNet.add(keras.layers.Dense(n_saidas, activation='softmax'))\n",
        "  return AlexNet\n",
        "\n",
        "AlexNet = AlexNet_model()\n",
        "\n",
        "\n",
        "AlexNet.summary()"
      ],
      "metadata": {
        "id": "2tVdSTW0J_uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        featurewise_center=True,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization = False,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode='nearest',\n",
        "        rotation_range = 45,\n",
        "        )\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "        samplewise_std_normalization = True)\n",
        "\n",
        "train_gen = train_datagen.flow(X_train, y_train, batch_size=32)\n",
        "test_gen = train_datagen.flow(X_test, y_test, batch_size=32)\n",
        "\n",
        "def test_data_augmentation():\n",
        "  fig, (ax1, ax2) = plt.subplots(2, 4, figsize = (12, 6))\n",
        "  for c_ax1, c_ax2, (train_img, _), (test_img, _) in zip(ax1, ax2, train_gen, test_gen):\n",
        "      c_ax1.imshow(train_img[0,:,:,:])\n",
        "      c_ax1.set_title('Train Image')\n",
        "      c_ax1.axis('off')\n",
        "\n",
        "      c_ax2.imshow(test_img[0,:,:,:])\n",
        "      c_ax2.set_title('Test Image')\n",
        "      c_ax2.axis('off')\n",
        "\n",
        "test_data_augmentation()"
      ],
      "metadata": {
        "id": "8dkCPGe0ValA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AlexNet.compile(loss=loss,\n",
        "              optimizer= adam_optimizer,\n",
        "               metrics=metrics_evaluation)\n",
        "\n",
        "\n",
        "hist_AlexNet = AlexNet.fit_generator(train_gen,\n",
        "                      steps_per_epoch=10,\n",
        "                      epochs = epochs, \n",
        "                      callbacks =[callback],\n",
        "                      validation_data=test_gen, \n",
        "                      validation_steps=10)\n",
        "\n",
        "# Salva os configs\n",
        "with open(config_dir + 'CNN_AlexNet' + tag + '.json', 'w') as f:\n",
        "    json.dump(AlexNet.get_config(), f)\n",
        "\n",
        "# Salva os erros\n",
        "with open(erro_dir + 'CNN_AlexNet' + tag + '.json', 'w') as f:\n",
        "    json.dump(hist_AlexNet.history, f)\n",
        "\n",
        "# Salva o modelo\n",
        "AlexNet.save(model_save_dir + 'CNN_AlexNet' + tag )"
      ],
      "metadata": {
        "id": "gijoLA5aKmTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(label, hist_obj, save=True):\n",
        "\n",
        "  plt.plot(hist_obj.history['loss'])\n",
        "  plt.plot(hist_obj.history['val_loss'])\n",
        "  plt.title('Loss')\n",
        "  plt.legend([\"CNN - Treinamento\", \"CNN - Validação\"], loc=\"best\")\n",
        "  if save:\n",
        "    plt.savefig(erro_dir + label + '_' + tag + '_loss_graph'  + '.png')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(hist_obj.history['categorical_accuracy'])\n",
        "  plt.plot(hist_obj.history['val_categorical_accuracy'])\n",
        "  plt.title('Acurácia')\n",
        "  plt.legend([\"CNN - Treinamento\", \"CNN - Validação\"], loc=\"best\")\n",
        "  if save:\n",
        "    plt.savefig(erro_dir +  label + '_' + tag + '_accuracy'  + '.png')\n",
        "  plt.show()\n",
        "\n",
        "plot_history('CNN_AlexNet', hist_AlexNet)"
      ],
      "metadata": {
        "id": "YN4bFfy1Ulzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Treinamento:\")\n",
        "score_tr = AlexNet.evaluate(X_train, y_train, verbose = 1, batch_size=batch_size)\n",
        "print(\"Teste:\")\n",
        "score_Te = AlexNet.evaluate(X_test, y_test, verbose = 1, batch_size=batch_size)\n",
        "\n",
        "# Salva performance pro log\n",
        "\n",
        "log={}\n",
        "log['CNN_AlexNet' + tag] = {}\n",
        "log['CNN_AlexNet' + tag]['metrics'] = {'loss_train':score_tr[0], 'categorical_accuracy_train':score_tr[1], 'auc_1_train':score_tr[2],\n",
        "       'loss_val':score_Te[0], 'categorical_accuracy_val':score_Te[1], 'auc_1_val':score_Te[2]}\n",
        "\n",
        "# Salva as metricas\n",
        "with open(log_dir + 'CNNs' + tag + '.json', 'w') as f:\n",
        "    json.dump(log, f)"
      ],
      "metadata": {
        "id": "wnfTvIqYUli1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning e MobileNet"
      ],
      "metadata": {
        "id": "cj1og7BKhRWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "base_model =  tf.keras.applications.MobileNetV2(input_shape=X_train.shape[1:],\n",
        "                                               include_top=True,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "base_model.summary()\n",
        "\n",
        "nb_layers = len(base_model.layers)\n",
        "print(base_model.layers[nb_layers - 2].name)\n",
        "print(base_model.layers[nb_layers - 1].name)"
      ],
      "metadata": {
        "id": "L4rWJD_3JLM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augmenter():\n",
        "    '''\n",
        "    Create a Sequential model composed of 2 layers\n",
        "    Returns:\n",
        "        tf.keras.Sequential\n",
        "    '''\n",
        "    data_augmentation = tf.keras.Sequential()\n",
        "    data_augmentation.add(RandomFlip('horizontal'))\n",
        "    data_augmentation.add(RandomRotation(0.2))\n",
        "    \n",
        "    return data_augmentation\n",
        "\n",
        "\n",
        "def celeb_mobel(data_augmentation=data_augmenter(), preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input):\n",
        "    ''' Cria modelo a partir modelo baseline\n",
        "    Arguments:\n",
        "        data_augmentation -- função de data augmentation\n",
        "        preprocess_input -- função de preprocessamento\n",
        "\n",
        "    Retorna:\n",
        "        tf.keras.model\n",
        "    '''\n",
        "        \n",
        "    base_model = tf.keras.applications.MobileNetV2(input_shape=X_train.shape[1:],\n",
        "                                                   include_top=False, \n",
        "                                                   weights='imagenet')\n",
        "    \n",
        "    # Congela os pesos do modelo\n",
        "    # base_model.trainable = False \n",
        "\n",
        "    # Cria input conforme as dimensões de entrada (deve ser o mesmo da FaceNet)\n",
        "    inputs = tf.keras.Input(shape=input_shape) \n",
        "    \n",
        "    # Aplica data augmentation nos inputs\n",
        "    x = data_augmentation(inputs)\n",
        "    \n",
        "    # Preprocessamento usando os mesmo pesos que o modelo foi treinado\n",
        "    x = preprocess_input(x) \n",
        "    \n",
        "    # Coloca training to False para não mostrar estatística do treino\n",
        "    x = base_model(x, training=True) \n",
        "    \n",
        "    # Usa average pooling para sumarizar as informações dos canais\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x) \n",
        "\n",
        "    # include dropout c/  p=0.2 (evitar sobreajuste)\n",
        "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
        "        \n",
        "    # Adiciona a camada de saída\n",
        "    outputs =  tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "        \n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "JBQmNKZdQL5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CelebModel = celeb_mobel()"
      ],
      "metadata": {
        "id": "8A0obXfZRlP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CelebModel.summary()"
      ],
      "metadata": {
        "id": "USxxcPxNRsqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CelebModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "               metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.AUC()])"
      ],
      "metadata": {
        "id": "HLiEVGlmSCyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200) # Parada\n",
        "\n",
        "hist_CelebModel = CelebModel.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.1,\n",
        "                    use_multiprocessing= True,\n",
        "                    callbacks=[callback],\n",
        "                    epochs=epochs, \n",
        "                    validation_data=(X_test, y_test),\n",
        "                    verbose=1)\n",
        "\n",
        "\n",
        "# Salva os configs\n",
        "with open(config_dir + 'CNN_Celeb' + tag + '.config', 'wb') as f:\n",
        "    pickle.dump(CelebModel.get_config(), f)\n",
        "\n",
        "# Salva os erros\n",
        "with open(erro_dir + 'CNN_Celeb' + tag + '.json', 'w') as f:\n",
        "    json.dump(hist_CelebModel.history, f)\n",
        "\n",
        "# Salve o modelo\n",
        "CelebModel.save(model_save_dir + 'CNN_Celeb' + tag )"
      ],
      "metadata": {
        "id": "Zrr_lBzXSESL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4hehMBXGh5GC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotta graficos\n",
        "plot_history('CelebModel',hist_CelebModel)"
      ],
      "metadata": {
        "id": "Oz4m9EXZrz8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Valida\n",
        "print(\"Treinamento:\")\n",
        "score_tr = CelebModel.evaluate(X_train, y_train, verbose = 1, batch_size=batch_size)\n",
        "print(\"Teste:\")\n",
        "score_Te = CelebModel.evaluate(X_test, y_test, verbose = 1, batch_size=batch_size)\n",
        "\n",
        "log['CelebModel' + tag] = {}\n",
        "log['CelebModel' + tag]['metrics'] = {'loss_train':score_tr[0], 'categorical_accuracy_train':score_tr[1], 'auc_1_train':score_tr[2],\n",
        "       'loss_val':score_Te[0], 'categorical_accuracy_val':score_Te[1], 'auc_1_val':score_Te[2]}\n",
        "\n",
        "# Salva as metricas\n",
        "with open(log_dir + 'CNNs' + tag + '.json', 'w') as f:\n",
        "    json.dump(log, f)"
      ],
      "metadata": {
        "id": "LQ6WutSIONzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_resultados(df, analise_pred, acertos=True):\n",
        "\n",
        "  for i,row in analise_pred.query('acerto==@acertos').head(20).iterrows():\n",
        "    fig, ax = plt.subplots(1,3, figsize=(10,6))\n",
        "\n",
        "    ax[0].axis('off')\n",
        "    ax[0].imshow(row['images'], cmap=plt.cm.gray)\n",
        "    ax[0].set_title('image')\n",
        "\n",
        "    real = df[df['class']==row['class']]['images'][0]\n",
        "    predicted = df[df['class']==row['class_pred']]['images'][0]\n",
        "\n",
        "    ax[1].axis('off')\n",
        "    ax[1].imshow(real, cmap=plt.cm.gray)\n",
        "    ax[1].set_title('real: person:{}'.format(row['class']))\n",
        "\n",
        "    ax[2].axis('off')\n",
        "    ax[2].imshow(predicted, cmap=plt.cm.gray)\n",
        "    ax[2].set_title('pred (probs:{}) :person:{}'.format(row['class_pred_proba'], row['class_pred']))\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zz1xhH35Pxp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analise de Erros e Acertos"
      ],
      "metadata": {
        "id": "l17saR2PstC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analise_pred = pd.Series(y_test.argmax(axis=1)).map(conversor_classes_inv).to_frame().rename(columns={0:'class'}).merge(dataset_raw[~dataset_raw['class_n'].duplicated(keep='first')], \n",
        "                                                                                                         left_on='class',\n",
        "                                                                                                         right_on='class',\n",
        "                                                                                                         how='left')\n",
        "predictions_test = CelebModel.predict(X_test)\n",
        "analise_pred['class_pred'] = predictions_test.argmax(axis=1)\n",
        "analise_pred['class_pred']= analise_pred['class_pred'].map(conversor_classes_inv)\n",
        "analise_pred['class_pred_proba'] =np.max(predictions_test, axis=1)\n",
        "analise_pred['class_pred_proba']=analise_pred['class_pred_proba'].apply(lambda x:round(x,2))\n",
        "analise_pred['acerto'] = analise_pred['class']== analise_pred['class_pred']\n",
        "\n",
        "print('acertos')\n",
        "print_resultados(dataset_raw, analise_pred, acertos=True)\n",
        "\n",
        "print('erros')\n",
        "print_resultados(dataset_raw, analise_pred, acertos=False)"
      ],
      "metadata": {
        "id": "Qrx6pTj2Ovp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_other_samples(n_images=10):\n",
        "  imagens_path = '/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/CelebA/img_align_celeba.zip'\n",
        "  imgzip = zipfile.ZipFile(imagens_path)\n",
        "  inflist = imgzip.infolist()\n",
        "  all_images = {}\n",
        "\n",
        "  # Testando com imagens da classe 3\n",
        "  it=0\n",
        "  for f in tqdm(inflist):\n",
        "    file_name = f.filename.split('/')[1]\n",
        "    if file_name in keep_images:\n",
        "      it+=1\n",
        "    # if '.jpg' in file_name:\n",
        "      ifile = imgzip.open(f)\n",
        "      img = Image.open(ifile)\n",
        "      img_resize = resize(np.array(img), (128, 128))\n",
        "      all_images[file_name] = img_resize\n",
        "\n",
        "      if it>n_images:\n",
        "        return all_images\n",
        "\n"
      ],
      "metadata": {
        "id": "WuQ23hwj0yen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analise de amostras aleatórias do universo"
      ],
      "metadata": {
        "id": "C0ym3pgHsxyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "\n",
        "samples = test_other_samples(40)\n",
        "samples_test = np.array(list(samples.values()))\n",
        "preds= CelebModel.predict(samples_test)\n",
        "out = pd.Series(preds.argmax(axis=1)).map(conversor_classes_inv)"
      ],
      "metadata": {
        "id": "4qUZXZnq4TUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_analise = dataset_raw[dataset_raw['class'].isin(out.values)]\n",
        "for cont, (i,r) in enumerate(df_analise[~df_analise['class'].duplicated(keep='first')].iterrows()):\n",
        "  fig, axis = plt.subplots(1,2,figsize=(5,4))\n",
        "  axis[0].imshow(samples_test[cont])\n",
        "  axis[0].set_title('image')\n",
        "  axis[0].axis('off')\n",
        "  axis[1].imshow(r['images'])\n",
        "  axis[1].set_title('pred')\n",
        "  axis[1].axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "at3CNV6g5_70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W1E0ocRO6329"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}