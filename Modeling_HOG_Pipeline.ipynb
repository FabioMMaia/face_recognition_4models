{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabioMMaia/face_recognition_4models/blob/main/Modeling_HOG_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0jNKeNAIcwEN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from skimage import data, exposure\n",
        "from skimage.feature import hog,local_binary_pattern\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from numpy.random import seed\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "\n",
        "def norm_text(txt):\n",
        "  from unidecode import unidecode\n",
        "  return unidecode(txt).replace(' ','_').lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k9xlX-xef0d",
        "outputId": "f5c77a1a-395d-4111-fa64-09b187615297"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.8/dist-packages (1.3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzJSiIc4z8BG",
        "outputId": "c64d69bb-0055-4ab7-cf96-e1a4955f1938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "I9gEzU85sBo8"
      },
      "outputs": [],
      "source": [
        "config_dir = '/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/config/'\n",
        "model_save_dir = '/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/model/'\n",
        "erro_dir = '/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/error/'\n",
        "log_dir = '/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/log/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0HwQFYUYdKRx"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/Modelos_Implementações')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "At7N2h1tdKiJ"
      },
      "outputs": [],
      "source": [
        "import MLP as mlp # multilayer perceptron\n",
        "import Multinomial_LogReg # regressão logística com alpha variavel (bissecao)\n",
        "import R_LOG as r_log # regressão logística com alpha fixo\n",
        "import SVM_OVR # SVM one-versus-rest\n",
        "import ANN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "\n",
        "importlib.reload(ANN)\n",
        "importlib.reload(mlp)\n",
        "importlib.reload(Multinomial_LogReg)\n",
        "importlib.reload(r_log)\n",
        "importlib.reload(SVM_OVR)\n",
        "importlib.reload(ANN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2mrQXgKHxcZ",
        "outputId": "8c3c978c-c45d-4487-9ea5-09b97dc4411c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'ANN' from '/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/Modelos_Implementações/ANN.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ByYR7oyY_fFy"
      },
      "outputs": [],
      "source": [
        "class logfile():\n",
        "\n",
        "  def __init__(self, diretorio):\n",
        "    self.diretorio=diretorio\n",
        "\n",
        "  def start(self, tag, use_dateref=True):\n",
        "    if use_dateref:\n",
        "      tag = tag + '_' + datetime.now(pytz.timezone('America/Bahia')).strftime(\"%Y%m%d\")\n",
        "    self.save_file = open(self.diretorio +  tag + '.txt', 'w')\n",
        "    data_atual = datetime.now(pytz.timezone('America/Bahia')).strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "    print('Execução em:', data_atual, file=self.save_file)\n",
        "    \n",
        "  def end(self):\n",
        "    data_atual = datetime.now(pytz.timezone('America/Bahia')).strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "    print('Fim de Execução em:', data_atual, file=self.save_file)\n",
        "    self.save_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando Dataset - HOG"
      ],
      "metadata": {
        "id": "-fCP7qO9EMjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes=3\n",
        "ref = 'HOG' \n",
        "\n",
        "tag= 'hog' + '_'+ str(n_classes) + '_classes'\n",
        "with open(r'/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/Data/X_y_' + tag +'.obj', \"rb\") as f:\n",
        "    X,y = pickle.load(f)"
      ],
      "metadata": {
        "id": "nesCirIwjSTI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuMfnhFCv530",
        "outputId": "681908c4-771e-4e16-ca84-9e6b9bfdb50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (101, 4608)\n",
            "y shape: (101,)\n"
          ]
        }
      ],
      "source": [
        "print('X shape:', X.shape)\n",
        "print('y shape:', y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOgsjWL7dmDr",
        "outputId": "ad709980-23cf-42c5-87e2-b49dd7957e15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de pessoas: 3\n"
          ]
        }
      ],
      "source": [
        "# transformar categorias em one-hot-encoding: Saída\n",
        "saida = y.max()+1\n",
        "print(\"Quantidade de pessoas:\",saida)\n",
        "target = keras.utils.to_categorical(y, saida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY1ktd8gd2yM"
      },
      "source": [
        "# Train x Test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_separation(X, y):\n",
        "  x_train, x_test, y_train_n, y_test_n = train_test_split(X, y, test_size=0.30, random_state=42,stratify=y)\n",
        "\n",
        "  y_train = target[y.index.isin(y_train_n.index).flatten(),:]\n",
        "  y_test= target[y.index.isin(y_test_n.index).flatten(),:]\n",
        "\n",
        "  assert y_train.shape[0]== y_train_n.shape[0]\n",
        "  assert y_test.shape[0]== y_test_n.shape[0]\n",
        "\n",
        "  print('Shape',x_train.shape, x_test.shape, y_train.shape, y_test.shape,  y_train_n.shape, y_test_n.shape)\n",
        "\n",
        "  return x_train, x_test, y_train_n, y_test_n, y_train, y_test"
      ],
      "metadata": {
        "id": "Db0Ju9CS_GMa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uy10wPGxd59i"
      },
      "outputs": [],
      "source": [
        "def apply_PCA(n_pca, x_train,x_test):\n",
        "  pca = PCA(n_components=n_pca, random_state=42)\n",
        "  pca.fit(x_train)\n",
        "\n",
        "  print('variancia explicada:', sum(pca.explained_variance_ratio_))\n",
        "  x_train_pca = pca.transform(x_train)\n",
        "  x_test_pca = pca.transform(x_test)\n",
        "\n",
        "  x_train_pca_norm = (x_train_pca - x_train_pca.mean(axis=0))/  x_train_pca.std(axis=0)\n",
        "  x_test_pca_norm = (x_test_pca - x_train_pca.mean(axis=0))/  x_train_pca.std(axis=0)\n",
        "\n",
        "  return x_train_pca_norm, x_test_pca_norm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train_n, y_test_n, y_train, y_test = train_test_separation(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSD9cLfdEh1t",
        "outputId": "ae1e1b94-c477-4236-f1cd-f57853d3cb5c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape (70, 4608) (31, 4608) (70, 3) (31, 3) (70,) (31,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3uXcqftrpx0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0af5618-1c0f-4b16-cc0c-8a710c0423bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "variancia explicada: 0.864794452061688\n"
          ]
        }
      ],
      "source": [
        "X_train_pca, X_test_pca = apply_PCA(n_pca=50, x_train=X_train, x_test=X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unpack_dict_as_str(dicionario):\n",
        "  string=''\n",
        "\n",
        "  for k,v in dicionario.items():\n",
        "    string= string + str(k) + ':[ '\n",
        "    try:\n",
        "      for v_ in v:\n",
        "        string= string + str(v_) + ' '\n",
        "      string= string+'] '\n",
        "    except:\n",
        "      string= string + str(v) + '] '\n",
        "  return string.strip()\n",
        "\n",
        "# unpack_dict_as_str({'a':[2,5,6], 'b':[6,7]})"
      ],
      "metadata": {
        "id": "fWaBqU60YCPa"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline_integrated_onedim(nome_do_modelo, #nome do modelo\n",
        "                               classifier, # classificador\n",
        "                               param_iteracao, # parametro iteração - deve conter um dicionario com a lista de valores a ser iterado\n",
        "                               param_fixo,  # parametro fixo e respectivo valor (uma lista)\n",
        "                               data, # dicionario de treino e teste\n",
        "                               kf= KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "                               neural_network=False): #kfold\n",
        "\n",
        "  print('Pipeline de testes para o modelo:', nome_do_modelo)\n",
        "  X_train = data['X_train']\n",
        "  X_test = data['X_test']\n",
        "  y_train = data['y_train']\n",
        "  y_test = data['y_test']\n",
        "\n",
        "  log={}\n",
        "  log['exec_time'] = 'Execução em: {}'.format(datetime.now(pytz.timezone('America/Bahia')).strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
        "  log['model_name'] = nome_do_modelo\n",
        "  log['parametro_fixo'] = '{}:[{}]'.format(param_fixo[0], param_fixo[1])\n",
        "  log['parametro_variavel'] = unpack_dict_as_str(param_iteracao)\n",
        "  log['kfold'] = kf\n",
        "\n",
        "  best_acc_val = -1\n",
        "  best_model=None\n",
        "  best_param = None\n",
        "  it=0\n",
        "\n",
        "  for parametro, valores in param_iteracao.items():\n",
        "    cv_report = {}\n",
        "    for valor in valores:\n",
        "      it+=1\n",
        "\n",
        "      cv_report['cv_results_'+str(it)] = {}\n",
        "      print('Execução em: {}'.format(datetime.now(pytz.timezone('America/Bahia')).strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
        "      print(\"====================================================================\")\n",
        "      print('iteração:{}'.format(it))\n",
        "      param = {parametro:valor}\n",
        "      param[param_fixo[0]] = param_fixo[1]\n",
        "      print('Testando parametros:\\n', unpack_dict_as_str(param))\n",
        "      print(\"====================================================================\")\n",
        "      \n",
        "      cv_report['cv_results_'+str(it)]['cv_param']= unpack_dict_as_str(param)\n",
        "\n",
        "      for k_index,(train_index, val_index) in enumerate(kf.split(X_train)):\n",
        "        X_train_kf, X_val_kf = X_train[train_index], X_train[val_index]\n",
        "        y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        # Ajusta o parâmetro usando o dicionário\n",
        "        for k,v in param.items():\n",
        "          setattr(classifier,k,v)\n",
        "        \n",
        "        if neural_network:\n",
        "          classifier.fit(X_train_kf, y_train_kf,[X_val_kf,y_val_kf])\n",
        "        else:\n",
        "          classifier.fit(X_train_kf, y_train_kf)\n",
        "\n",
        "        acc_train = accuracy_score(classifier.predict(X_train_kf), y_train_kf)\n",
        "        acc_val = accuracy_score(classifier.predict(X_val_kf), y_val_kf)\n",
        "        acc_test = accuracy_score(classifier.predict(X_test), y_test)\n",
        "\n",
        "        if acc_val>best_acc_val:\n",
        "          best_model=classifier\n",
        "          best_param = param\n",
        "          k_index_best = k_index\n",
        "          best_acc_val=acc_val\n",
        "\n",
        "        cv_report['cv_results_'+str(it)]['acc_train_'+str(k_index)] = acc_train\n",
        "        cv_report['cv_results_'+str(it)]['acc_val_'+ str(k_index)] = acc_val\n",
        "        cv_report['cv_results_'+str(it)]['acc_test_'+ str(k_index)] = acc_test\n",
        "\n",
        "    log['cv_report']= cv_report\n",
        "\n",
        "    if neural_network:\n",
        "      best_model.fit(X_train, y_train,[X_test,y_test])\n",
        "    else:\n",
        "      best_model.fit(X_train, y_train)\n",
        "    \n",
        "    acc_train_best_model = accuracy_score(best_model.predict(X_train), y_train)\n",
        "    acc_test_best_model = accuracy_score(best_model.predict(X_test), y_test)\n",
        "    print('Melhor acurácia no validação obtida com os parametros {}. Treino final: {:.4f} Teste:{:.4f}'.format(unpack_dict_as_str(best_param),acc_train_best_model, acc_test_best_model))\n",
        "    print('Fim da Execução: {}'.format(datetime.now(pytz.timezone('America/Bahia')).strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
        "    \n",
        "    log['melhor_modelo_obj'] = best_model\n",
        "    log['best_param_k_fold'] = unpack_dict_as_str(best_param)\n",
        "    log['acc_train_best_model'] = acc_train_best_model\n",
        "    log['acc_test_best_model'] = acc_test_best_model\n",
        "\n",
        "    return log\n",
        "\n",
        "def dictlog_to_flat_table(log):\n",
        "  log_i = pd.DataFrame(log, index=[norm_text(modelo)])\n",
        "  cv_log_i = pd.DataFrame(log['cv_report']).T.reset_index().assign(modelo = norm_text(modelo))\n",
        "  cv_log_i = pd.merge(log_i,cv_log_i, left_index = True , right_on = 'modelo', how='outer').drop(columns='cv_report')\n",
        "  return cv_log_i"
      ],
      "metadata": {
        "id": "KoiQ6uaLIOaf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste com Modelos"
      ],
      "metadata": {
        "id": "Olv5yCORwFSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logs = pd.DataFrame()"
      ],
      "metadata": {
        "id": "wq87vRPhv1Rl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regressão Logística"
      ],
      "metadata": {
        "id": "7t7YCGZUyyzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = 'Regressão Logística Multinomial Passo Fixo'\n",
        "\n",
        "log = pipeline_integrated_onedim(nome_do_modelo=modelo, \n",
        "                          classifier= Multinomial_LogReg.MultinomialLogReg(),\n",
        "                          param_iteracao= {'alpha':[0.01, 0.1]},\n",
        "                          param_fixo=['theta',0.001],\n",
        "                          data={'X_train':X_train_pca, 'X_test':X_test_pca, 'y_train':y_train_n, 'y_test':y_test_n} )\n",
        "\n",
        "log_df = dictlog_to_flat_table(log)\n",
        "logs = logs.append(log_df,ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "8TCd4vHtWJAR",
        "outputId": "f89e5717-6669-4bca-9430-63c14d5e9cab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline de testes para o modelo: Regressão Logística Multinomial Passo Fixo\n",
            "Execução em: 21/01/2023 04:38:34\n",
            "====================================================================\n",
            "iteração:1\n",
            "Testando parametros:\n",
            " alpha:[ 0.01] theta:[ 0.001]\n",
            "====================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e88c044dc46b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodelo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Regressão Logística Multinomial Passo Fixo'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m log = pipeline_integrated_onedim(nome_do_modelo=modelo, \n\u001b[0m\u001b[1;32m      4\u001b[0m                           \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMultinomial_LogReg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultinomialLogReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           \u001b[0mparam_iteracao\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-7352e7f6cede>\u001b[0m in \u001b[0;36mpipeline_integrated_onedim\u001b[0;34m(nome_do_modelo, classifier, param_iteracao, param_fixo, data, kf, neural_network)\u001b[0m\n\u001b[1;32m     52\u001b[0m           \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_kf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_kf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val_kf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val_kf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m           \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_kf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_kf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_kf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_kf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Projeto ML/2022/Aprendizado de Maquinas/Projeto/Pipeline/Modelos_Implementações/Multinomial_LogReg.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0;31m# Calcula o gradiente e respectivamente sua norma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mgradE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0mnorm_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = 'Regressão Logística Multinomial com Bisseção'\n",
        "\n",
        "log = pipeline_integrated_onedim(nome_do_modelo=modelo, \n",
        "                          classifier= Multinomial_LogReg.MultinomialLogReg_bissecao(),\n",
        "                          param_iteracao= {'itmax_bissec':[5, 20]},\n",
        "                          param_fixo=['theta',0.001],\n",
        "                          data={'X_train':X_train_pca, 'X_test':X_test_pca, 'y_train':y_train_n, 'y_test':y_test_n} )\n",
        "\n",
        "log_df = dictlog_to_flat_table(log)\n",
        "logs = logs.append(log_df,ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyFaR2riwYtz",
        "outputId": "56991e73-e3d9-4d95-fc81-dcce2a731f58"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline de testes para o modelo: Regressão Logística Multinomial com Bisseção\n",
            "Execução em: 21/01/2023 04:40:55\n",
            "====================================================================\n",
            "iteração:1\n",
            "Testando parametros:\n",
            " itmax_bissec:[ 5] theta:[ 0.001]\n",
            "====================================================================\n",
            "iteracao: 0 norm_grad: 57.51986595801932\n",
            "it:9, norm_grad:0.0005595747362122309, J:0.00032973799011878875, alpha_b:744.863183991245, hl:1.8626266026320727e-07\n",
            "iteracao: 0 norm_grad: 59.79590115385518\n",
            "it:12, norm_grad:0.000562840907770286, J:0.0003621542811527742, alpha_b:628.6006380428204, hl:4.275852528756953e-09\n",
            "iteracao: 0 norm_grad: 61.593951124385825\n",
            "it:16, norm_grad:0.0006831700735120524, J:0.00030899904459795745, alpha_b:1108.8221526437587, hl:4.4065903492943217e-07\n",
            "iteracao: 0 norm_grad: 64.34191727833614\n",
            "it:9, norm_grad:0.0003449459726733767, J:0.0001886103834897421, alpha_b:622.4763022181273, hl:2.069586941735053e-08\n",
            "iteracao: 0 norm_grad: 61.29917390370516\n",
            "it:13, norm_grad:0.00018497032505066305, J:0.00010504084672818744, alpha_b:996.4515977677386, hl:1.4541554592137757e-08\n",
            "Execução em: 21/01/2023 04:40:55\n",
            "====================================================================\n",
            "iteração:2\n",
            "Testando parametros:\n",
            " itmax_bissec:[ 20] theta:[ 0.001]\n",
            "====================================================================\n",
            "iteracao: 0 norm_grad: 58.8857557315416\n",
            "it:9, norm_grad:0.00019179169546971014, J:0.00012904876124825425, alpha_b:1003.4662679804517, hl:1.5785658440381403e-08\n",
            "iteracao: 0 norm_grad: 62.18876104137436\n",
            "it:8, norm_grad:0.0004987412447789197, J:0.0001941394837530166, alpha_b:1133.5729409774526, hl:7.1821336344868346e-09\n",
            "iteracao: 0 norm_grad: 58.696697332075516\n",
            "it:12, norm_grad:0.0005419102047924258, J:0.00034565060467273644, alpha_b:647.242924474287, hl:1.3464378148418812e-07\n",
            "iteracao: 0 norm_grad: 59.41901016533309\n",
            "it:10, norm_grad:0.0009885124605714408, J:0.0003784688013579848, alpha_b:689.533417514427, hl:7.584035299402089e-07\n",
            "iteracao: 0 norm_grad: 59.54611630137035\n",
            "it:13, norm_grad:0.0009966618647487908, J:0.00032781413460603324, alpha_b:1328.401576232256, hl:1.9707695166100863e-06\n",
            "iteracao: 0 norm_grad: 71.41073399052382\n",
            "it:9, norm_grad:0.0002957535586851249, J:0.00015885852231974087, alpha_b:1125.043506324882, hl:3.7131021460600304e-08\n",
            "Melhor acurácia no validação obtida com os parametros itmax_bissec:[ 20] theta:[ 0.001]. Treino final: 1.0000 Teste:0.9355\n",
            "Fim da Execução: 21/01/2023 04:40:56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM"
      ],
      "metadata": {
        "id": "j50V1Z33zHM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = 'SVM Classificador Kernel RBF C=1'\n",
        "\n",
        "log = pipeline_integrated_onedim(nome_do_modelo=modelo, \n",
        "                          classifier=  SVM_OVR.SVM_one_vs_all(),\n",
        "                          param_iteracao= {'sigma':[0.01, 0.1,1]},\n",
        "                          param_fixo=['C',1],\n",
        "                          data={'X_train':X_train_pca, 'X_test':X_test_pca, 'y_train':y_train_n, 'y_test':y_test_n})\n",
        "\n",
        "log_df = dictlog_to_flat_table(log)\n",
        "logs = logs.append(log_df,ignore_index=True)"
      ],
      "metadata": {
        "id": "46TpRSsKzJgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = 'SVM Classificador Kernel RBF C=10'\n",
        "\n",
        "log = pipeline_integrated_onedim(nome_do_modelo=modelo, \n",
        "                          classifier=  SVM_OVR.SVM_one_vs_all(),\n",
        "                          param_iteracao= {'sigma':[0.01, 0.1,1]},\n",
        "                          param_fixo=['C',10],\n",
        "                          data={'X_train':X_train_pca, 'X_test':X_test_pca, 'y_train':y_train_n, 'y_test':y_test_n})\n",
        "\n",
        "log_df = dictlog_to_flat_table(log)\n",
        "logs = logs.append(log_df,ignore_index=True)"
      ],
      "metadata": {
        "id": "DkuGV_aN4_Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = 'SVM Classificador Kernel RBF C=100'\n",
        "\n",
        "log = pipeline_integrated_onedim(nome_do_modelo=modelo, \n",
        "                          classifier=  SVM_OVR.SVM_one_vs_all(),\n",
        "                          param_iteracao= {'sigma':[0.01, 0.1,1]},\n",
        "                          param_fixo=['C',100],\n",
        "                          data={'X_train':X_train_pca, 'X_test':X_test_pca, 'y_train':y_train_n, 'y_test':y_test_n})\n",
        "\n",
        "log_df = dictlog_to_flat_table(log)\n",
        "logs = logs.append(log_df)"
      ],
      "metadata": {
        "id": "2snFIIhe5O2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "x2EcgwPG6R0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = 'MultiLayer Perceptron alpha 0.1'\n",
        "\n",
        "log = pipeline_integrated_onedim(nome_do_modelo=modelo, \n",
        "                          classifier=  ANN.RNA(),\n",
        "                          param_iteracao= {'h':[5,10]},\n",
        "                          param_fixo=['alpha',0.1],\n",
        "                          data={'X_train':X_train_pca, 'X_test':X_test_pca, 'y_train':y_train_n, 'y_test':y_test_n},\n",
        "                          neural_network=True)\n",
        "\n",
        "log_df = dictlog_to_flat_table(log)\n",
        "logs = logs.append(log_df,ignore_index=True)"
      ],
      "metadata": {
        "id": "tl_AuVKW6UEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "logs.head(3)"
      ],
      "metadata": {
        "id": "zZ1NeTjf4gzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Informações Melhor/Pior Modelo"
      ],
      "metadata": {
        "id": "8ZrLT-JZGohf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = tag + '_log_full'\n",
        "\n",
        "logs.to_excel(log_dir +label + '.xlsx')"
      ],
      "metadata": {
        "id": "uRMHgRTbRD4o"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_error(label):\n",
        "  errorFile = open(erro_dir +label + '.txt', 'w') \n",
        "  print('Execução em: {}'.format(datetime.now(pytz.timezone('America/Bahia')).strftime(\"%d/%m/%Y %H:%M:%S\")) , file=errorFile)\n",
        "\n",
        "  out=''\n",
        "  for i,r in melhor_modelo_infos.filter(like='acc').T.reset_index().iterrows():\n",
        "    out=out + str(r['index']) + ':' + str(r[0]) + '\\n'\n",
        "  print(out, file=errorFile)\n",
        "  errorFile.close()"
      ],
      "metadata": {
        "id": "U6Q5Jm6tHS_J"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = tag + '_' + 'melhor'\n",
        "\n",
        "melhor_modelo_infos = logs.sort_values(by='acc_test_best_model',ascending=False).head(1)\n",
        "\n",
        "# Salva mehlhor modelo\n",
        "melhor_modelo = melhor_modelo_infos['melhor_modelo_obj'].iloc[0]\n",
        "with open(model_save_dir + label +'.obj', 'wb') as fp:\n",
        "  pickle.dump(melhor_modelo, fp)\n",
        "\n",
        "# Salva o erro\n",
        "save_error(label)\n",
        "\n",
        "#Salva o config\n",
        "melhor_modelo_infos.drop(columns = melhor_modelo_infos.filter(like='acc').columns).T.rename(columns={0:'config'}).to_csv(config_dir + label  +'.txt', sep=':')"
      ],
      "metadata": {
        "id": "da4yaCoVGDtZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = tag + '_' + 'pior'\n",
        "\n",
        "pior_modelo_infos = logs.sort_values(by='acc_test_best_model',ascending=False).tail(1)\n",
        "\n",
        "# Salva pior modelo\n",
        "pior = pior_modelo_infos['melhor_modelo_obj'].iloc[0]\n",
        "with open(model_save_dir + label +'.obj', 'wb') as fp:\n",
        "  pickle.dump(pior, fp)\n",
        "\n",
        "# Salva o erro\n",
        "save_error(label)\n",
        "\n",
        "#Salva o config\n",
        "melhor_modelo_infos.drop(columns = pior_modelo_infos.filter(like='acc').columns).T.rename(columns={0:'config'}).to_csv(config_dir + label  +'.txt', sep=':')"
      ],
      "metadata": {
        "id": "B-XcQhGYJaMA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDAHtj_0RrD4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}